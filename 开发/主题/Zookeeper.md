# Zookeeper

## 常见使用常见
- 数据发布/订阅
- 负载均衡
- 分布式协调/通知
- 集群管理
- master管理
- 分布式锁
排他锁（写锁），利用zookeeper同级节点的唯一性，在需要获取排他锁时，所有的客户端通过调用create()接口，在/exclusive_lock节点下创建临时子节点/exclusive_lock/lock，最终只有一个客户端能创建成功，那么此客户端就获得了分布式锁。同时，所有没有获取到锁的客户端可以在/exclusive_lock节点上注册一个子节点变更的watcher监听事件，以便重新争取获得锁。
- 分布式队列

## 数据模型
在 Zookeeper 中，数据是由 znode（节点）组成，以 key/value 形式存储的，整体结构类似于 linux 文件系统的树形结构，其中根路径为 /

## 节点特性
- 同一级节点（key）名称是唯一的
- 创建节点需要带上全路径
- session关闭，临时节点自动清除（注意TCP断开，并不代表会话关闭）
- 自动创建顺序节点，zk会将10位序列号附加在原始键名后面
- delete命令只能一层一层的删除节点
- 新版本的deleteall可以递归删除节点
- 事件监听机制类似于观察者模式，watch流程是客户端向服务端某个节点路径上注册一个watcher，同时客户端也会存储特定的 watcher，
当节点数据或子节点发生变化时，服务端通知客户端，客户端进行回调处理。特别注意：监听事件被单次触发后，事件就失效了

## zk中每个节点可以存储多大的键值
1M，但是建议不要超过1KB

## zk集群数量限制
必须是2N+1的个数，最多容忍N个节点失效（不考虑Observer节点）

## zk三个端口的作用
2181对客户端提供服务，2888集群内机器通信使用，3888选举leader使用

## 常用命令
./zkServer.sh status查看节点状态，./zkServer.sh start启动，./zkServer.sh stop关闭服务

## zk的Java客户端
原生的API，Netflix的curator包

## 选举的几种状态
looking，following，observing，leading

## CAP理论？
CAP（Consistency、Availability、Partition tolerance）理论指出对于一个分布式系统来说，不可能同时满足以下三点，最多满足两个：一致性：在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性，在一致性的需求下，当执行更新操作后，应该保证系统的数据仍然处于一致的状态；可用性：每次请求都能获取到正确的响应，但是不保证获取的数据为最新数据；分区容错性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。在这三个基本需求中，最多只能同时满足其中的两项，P是必须的，因此只能在CP和AP中选择，zookeeper保证的是CP，对比spring cloud系统中的注册中心eruka实现的是AP。
## BASE理论
BASE是Basically Available（基本可用）、Soft-state（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。基本可用：在分布式系统出现故障时，允许损失部分可用性（服务降级、页面降级）；软状态：允许分布式系统出现中间状态，而且中间状态不影响系统的可用性，这里的中间状态是指不同的data replication（数据备份节点）之间的数据更新可以出现延时的最终一致性；最终一致性：经过一段时间达到一致性。BASE理论是对CAP 中的一致性和可用性进行权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。
4.	强一致性、弱一致性和最终一致性？

## zk使用什么协议保证一致性？
ZAB协议，分为消息广播和故障恢复两部分。消息广播，zk使用单一Leader来接收和处理客户端的所有事务请求，并采用ZAB协议的原子广播，将事务请求以Proposal提议的形式广播到所有的Follower节点，当集群中有过半的Follower 服务器进行正确的ACK反馈，那么Leader就会再次向所有的Follower服务器发送commit消息，将此次提案进行提交。这个过程可以简称为2pc事务提交，注意 Observer 节点只负责同步 Leader数据，不参与2PC数据同步过程。故障恢复，ZAB协议的恢复模式使用了以下策略，选举zxid最大的节点作为新的leader，新leader将事务日志中尚未提交的消息进行处理。

## 选举中比较重要的几个参数
服务器ID，编号越大在选举算法中权重越大，事务ID（Zxid）值越大说明数据越新，权重越大，逻辑时钟，同一轮投票中逻辑时钟是一样的，每投一轮值会增加

## 集群启动时的选举流程
每个节点启动的时候都处于LOOKING状态，接下来就开始进行选举，这里选取三台机器组成的集群为例，第一台服务器server1启动时，无法进行选举，当第二台服务器server2启动时，两台机器相互通信，进入leader选举过程。
A.	每台server发出一个投票，由于是初始情况，server1和server2都将自己作为leader进行投票，每次投票包含所推举的服务器myid、zxid、epoch（逻辑时钟），使用(myid，zxid)表示，此时server1投票为(1, 0)，server2投票为(2, 0)，然后将各自投票发送给集群中其他机器；
B.	接收来自各个服务器的投票，集群中的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票（epoch）、是否来自 LOOKING 状态的服务器；
C.	分别处理投票，针对每一次投票，服务器都需要将其他服务器的投票和自己的投票进行对比，对比规则如下：
a)	优先比较epoch；
b)	检查zxid，zxid比较大的服务器优先作为leader；
c)	如果zxid相同，那么就比较myid，myid较大的服务器作为leader；
D.	统计投票，每次投票后，服务器统计投票信息，判断是有过半机器具有相同的投票，server1、server2 都统计出集群中有两台机器接受了(2, 0)的投票信息，此时已经选出了server2为leader节点；
E.	改变服务器状态，一旦确定了leader，每个服务器响应更新自己的状态，如果是follower，那么就变更为FOLLOWING，如果是leader，变更为LEADING，此时 server3继续启动，直接加入变更自己为FOLLOWING；

## 集群运行中的投票
当集群中leader服务器出现宕机或者不可用情况时，整个集群无法对外提供服务，进入新一轮的leader选举：
A.	变更状态，leader 挂后，其他非 Oberver服务器将自身服务器状态变更为 LOOKING；
B.	每个 server 发出一个投票，在运行期间，每个服务器上 zxid 可能不同；
C.	处理投票，规则同启动过程；
D.	统计投票，与启动过程相同；
E.	改变服务器状态，与启动过程相同；
